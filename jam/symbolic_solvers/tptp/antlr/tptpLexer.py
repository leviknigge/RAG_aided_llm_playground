# Generated from tptp.g4 by ANTLR 4.9.3
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
    from typing import TextIO
else:
    from typing.io import TextIO



def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2 ")
        buf.write("\u00c5\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
        buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
        buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
        buf.write("\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30")
        buf.write("\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36")
        buf.write("\t\36\4\37\t\37\3\2\3\2\3\2\3\2\3\2\3\2\3\3\3\3\3\3\3")
        buf.write("\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\4\5\4R\n\4\3\4\3\4\3")
        buf.write("\4\3\4\3\4\3\5\5\5Z\n\5\3\5\3\5\3\6\3\6\5\6`\n\6\3\6\3")
        buf.write("\6\3\6\3\6\3\7\6\7g\n\7\r\7\16\7h\3\7\3\7\3\b\3\b\7\b")
        buf.write("o\n\b\f\b\16\br\13\b\3\b\3\b\3\t\3\t\3\t\3\t\7\tz\n\t")
        buf.write("\f\t\16\t}\13\t\3\t\3\t\3\t\3\t\3\t\3\n\3\n\3\n\3\n\3")
        buf.write("\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3\20")
        buf.write("\3\20\3\21\3\21\3\21\3\21\3\22\3\22\3\22\3\22\3\23\3\23")
        buf.write("\3\24\3\24\3\25\3\25\3\26\3\26\3\27\3\27\3\30\3\30\3\30")
        buf.write("\5\30\u00aa\n\30\3\31\3\31\7\31\u00ae\n\31\f\31\16\31")
        buf.write("\u00b1\13\31\3\32\3\32\7\32\u00b5\n\32\f\32\16\32\u00b8")
        buf.write("\13\32\3\33\3\33\3\33\3\34\3\34\3\34\3\35\3\35\3\36\3")
        buf.write("\36\3\37\3\37\3{\2 \3\3\5\4\7\5\t\6\13\7\r\b\17\t\21\n")
        buf.write("\23\13\25\f\27\r\31\16\33\17\35\20\37\21!\22#\23%\24\'")
        buf.write("\25)\26+\27-\30/\31\61\32\63\33\65\34\67\359\36;\37= ")
        buf.write("\3\2\7\4\2\13\13\"\"\4\2\f\f\17\17\3\2C\\\3\2c|\3\2\62")
        buf.write(";\2\u00ce\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2")
        buf.write("\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2")
        buf.write("\2\2\23\3\2\2\2\2\25\3\2\2\2\2\27\3\2\2\2\2\31\3\2\2\2")
        buf.write("\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2\2!\3\2\2\2\2#")
        buf.write("\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2")
        buf.write("\2-\3\2\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63\3\2\2\2\2\65")
        buf.write("\3\2\2\2\2\67\3\2\2\2\29\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2")
        buf.write("\3?\3\2\2\2\5E\3\2\2\2\7Q\3\2\2\2\tY\3\2\2\2\13]\3\2\2")
        buf.write("\2\rf\3\2\2\2\17l\3\2\2\2\21u\3\2\2\2\23\u0083\3\2\2\2")
        buf.write("\25\u0087\3\2\2\2\27\u0089\3\2\2\2\31\u008b\3\2\2\2\33")
        buf.write("\u008d\3\2\2\2\35\u008f\3\2\2\2\37\u0091\3\2\2\2!\u0094")
        buf.write("\3\2\2\2#\u0098\3\2\2\2%\u009c\3\2\2\2\'\u009e\3\2\2\2")
        buf.write(")\u00a0\3\2\2\2+\u00a2\3\2\2\2-\u00a4\3\2\2\2/\u00a9\3")
        buf.write("\2\2\2\61\u00ab\3\2\2\2\63\u00b2\3\2\2\2\65\u00b9\3\2")
        buf.write("\2\2\67\u00bc\3\2\2\29\u00bf\3\2\2\2;\u00c1\3\2\2\2=\u00c3")
        buf.write("\3\2\2\2?@\7c\2\2@A\7z\2\2AB\7k\2\2BC\7q\2\2CD\7o\2\2")
        buf.write("D\4\3\2\2\2EF\7e\2\2FG\7q\2\2GH\7p\2\2HI\7l\2\2IJ\7g\2")
        buf.write("\2JK\7e\2\2KL\7v\2\2LM\7w\2\2MN\7t\2\2NO\7g\2\2O\6\3\2")
        buf.write("\2\2PR\7\17\2\2QP\3\2\2\2QR\3\2\2\2RS\3\2\2\2ST\7\f\2")
        buf.write("\2TU\6\4\2\2UV\3\2\2\2VW\b\4\2\2W\b\3\2\2\2XZ\7\17\2\2")
        buf.write("YX\3\2\2\2YZ\3\2\2\2Z[\3\2\2\2[\\\7\f\2\2\\\n\3\2\2\2")
        buf.write("]_\7^\2\2^`\7\17\2\2_^\3\2\2\2_`\3\2\2\2`a\3\2\2\2ab\7")
        buf.write("\f\2\2bc\3\2\2\2cd\b\6\2\2d\f\3\2\2\2eg\t\2\2\2fe\3\2")
        buf.write("\2\2gh\3\2\2\2hf\3\2\2\2hi\3\2\2\2ij\3\2\2\2jk\b\7\2\2")
        buf.write("k\16\3\2\2\2lp\7\'\2\2mo\n\3\2\2nm\3\2\2\2or\3\2\2\2p")
        buf.write("n\3\2\2\2pq\3\2\2\2qs\3\2\2\2rp\3\2\2\2st\b\b\3\2t\20")
        buf.write("\3\2\2\2uv\7\61\2\2vw\7,\2\2w{\3\2\2\2xz\13\2\2\2yx\3")
        buf.write("\2\2\2z}\3\2\2\2{|\3\2\2\2{y\3\2\2\2|~\3\2\2\2}{\3\2\2")
        buf.write("\2~\177\7,\2\2\177\u0080\7\61\2\2\u0080\u0081\3\2\2\2")
        buf.write("\u0081\u0082\b\t\3\2\u0082\22\3\2\2\2\u0083\u0084\7h\2")
        buf.write("\2\u0084\u0085\7q\2\2\u0085\u0086\7h\2\2\u0086\24\3\2")
        buf.write("\2\2\u0087\u0088\7.\2\2\u0088\26\3\2\2\2\u0089\u008a\7")
        buf.write("\60\2\2\u008a\30\3\2\2\2\u008b\u008c\7\u0080\2\2\u008c")
        buf.write("\32\3\2\2\2\u008d\u008e\7(\2\2\u008e\34\3\2\2\2\u008f")
        buf.write("\u0090\7~\2\2\u0090\36\3\2\2\2\u0091\u0092\7?\2\2\u0092")
        buf.write("\u0093\7@\2\2\u0093 \3\2\2\2\u0094\u0095\7>\2\2\u0095")
        buf.write("\u0096\7?\2\2\u0096\u0097\7@\2\2\u0097\"\3\2\2\2\u0098")
        buf.write("\u0099\7>\2\2\u0099\u009a\7\u0080\2\2\u009a\u009b\7@\2")
        buf.write("\2\u009b$\3\2\2\2\u009c\u009d\7#\2\2\u009d&\3\2\2\2\u009e")
        buf.write("\u009f\7A\2\2\u009f(\3\2\2\2\u00a0\u00a1\t\4\2\2\u00a1")
        buf.write("*\3\2\2\2\u00a2\u00a3\t\5\2\2\u00a3,\3\2\2\2\u00a4\u00a5")
        buf.write("\t\6\2\2\u00a5.\3\2\2\2\u00a6\u00aa\5)\25\2\u00a7\u00aa")
        buf.write("\5+\26\2\u00a8\u00aa\5-\27\2\u00a9\u00a6\3\2\2\2\u00a9")
        buf.write("\u00a7\3\2\2\2\u00a9\u00a8\3\2\2\2\u00aa\60\3\2\2\2\u00ab")
        buf.write("\u00af\5)\25\2\u00ac\u00ae\5/\30\2\u00ad\u00ac\3\2\2\2")
        buf.write("\u00ae\u00b1\3\2\2\2\u00af\u00ad\3\2\2\2\u00af\u00b0\3")
        buf.write("\2\2\2\u00b0\62\3\2\2\2\u00b1\u00af\3\2\2\2\u00b2\u00b6")
        buf.write("\5+\26\2\u00b3\u00b5\5/\30\2\u00b4\u00b3\3\2\2\2\u00b5")
        buf.write("\u00b8\3\2\2\2\u00b6\u00b4\3\2\2\2\u00b6\u00b7\3\2\2\2")
        buf.write("\u00b7\64\3\2\2\2\u00b8\u00b6\3\2\2\2\u00b9\u00ba\7*\2")
        buf.write("\2\u00ba\u00bb\b\33\4\2\u00bb\66\3\2\2\2\u00bc\u00bd\7")
        buf.write("+\2\2\u00bd\u00be\b\34\5\2\u00be8\3\2\2\2\u00bf\u00c0")
        buf.write("\7]\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7_\2\2\u00c2<\3\2\2")
        buf.write("\2\u00c3\u00c4\7<\2\2\u00c4>\3\2\2\2\f\2QY_hp{\u00a9\u00af")
        buf.write("\u00b6\6\b\2\2\2\4\2\3\33\2\3\34\3")
        return buf.getvalue()


class tptpLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    T__0 = 1
    T__1 = 2
    IGNORE_NEWLINE = 3
    NEWLINE = 4
    LINE_ESCAPE = 5
    WHITESPACE = 6
    SL_COMMENT = 7
    BL_COMMENT = 8
    FOF_ID = 9
    SEP = 10
    DOT = 11
    NOT = 12
    CONJ = 13
    DISJ = 14
    IMPL = 15
    BICOND = 16
    XOR = 17
    FORALL = 18
    EXISTS = 19
    UPPER_ALPHA = 20
    LOWER_ALPHA = 21
    DIGIT = 22
    ALPHA_NUMERIC = 23
    UPPER_WORD = 24
    LOWER_WORD = 25
    LPAREN = 26
    RPAREN = 27
    LSQPAREN = 28
    RSQPAREN = 29
    COLON = 30

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'axiom'", "'conjecture'", "'fof'", "','", "'.'", "'~'", "'&'", 
            "'|'", "'=>'", "'<=>'", "'<~>'", "'!'", "'?'", "'('", "')'", 
            "'['", "']'", "':'" ]

    symbolicNames = [ "<INVALID>",
            "IGNORE_NEWLINE", "NEWLINE", "LINE_ESCAPE", "WHITESPACE", "SL_COMMENT", 
            "BL_COMMENT", "FOF_ID", "SEP", "DOT", "NOT", "CONJ", "DISJ", 
            "IMPL", "BICOND", "XOR", "FORALL", "EXISTS", "UPPER_ALPHA", 
            "LOWER_ALPHA", "DIGIT", "ALPHA_NUMERIC", "UPPER_WORD", "LOWER_WORD", 
            "LPAREN", "RPAREN", "LSQPAREN", "RSQPAREN", "COLON" ]

    ruleNames = [ "T__0", "T__1", "IGNORE_NEWLINE", "NEWLINE", "LINE_ESCAPE", 
                  "WHITESPACE", "SL_COMMENT", "BL_COMMENT", "FOF_ID", "SEP", 
                  "DOT", "NOT", "CONJ", "DISJ", "IMPL", "BICOND", "XOR", 
                  "FORALL", "EXISTS", "UPPER_ALPHA", "LOWER_ALPHA", "DIGIT", 
                  "ALPHA_NUMERIC", "UPPER_WORD", "LOWER_WORD", "LPAREN", 
                  "RPAREN", "LSQPAREN", "RSQPAREN", "COLON" ]

    grammarFileName = "tptp.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.9.3")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None

    nesting = 0

    def action(self, localctx:RuleContext, ruleIndex:int, actionIndex:int):
        if self._actions is None:
            actions = dict()
            actions[25] = self.LPAREN_action 
            actions[26] = self.RPAREN_action 
            self._actions = actions
        action = self._actions.get(ruleIndex, None)
        if action is not None:
            action(localctx, actionIndex)
        else:
            raise Exception("No registered action for:" + str(ruleIndex))


    def LPAREN_action(self, localctx:RuleContext , actionIndex:int):
        if actionIndex == 0:
            self.nesting +=1
     

    def RPAREN_action(self, localctx:RuleContext , actionIndex:int):
        if actionIndex == 1:
            self.nesting -=1
     

    def sempred(self, localctx:RuleContext, ruleIndex:int, predIndex:int):
        if self._predicates is None:
            preds = dict()
            preds[2] = self.IGNORE_NEWLINE_sempred
            self._predicates = preds
        pred = self._predicates.get(ruleIndex, None)
        if pred is not None:
            return pred(localctx, predIndex)
        else:
            raise Exception("No registered predicate for:" + str(ruleIndex))

    def IGNORE_NEWLINE_sempred(self, localctx:RuleContext, predIndex:int):
            if predIndex == 0:
                return self.nesting>0
         


