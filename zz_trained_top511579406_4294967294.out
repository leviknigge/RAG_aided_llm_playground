============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
/var/spool/slurm/slurmd/job11579406/slurm_script: line 18: /home/knigge/.bashrc: No such file or directory
/home/lknigge/.conda/envs/thesis-env/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/home/lknigge/.conda/envs/thesis-env/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[May 05, 21:23:34] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...
/home/lknigge/.conda/envs/thesis-env/lib/python3.12/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/home/lknigge/.conda/envs/thesis-env/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
index loaded
Loading searcher for index test for the first time... This may take a few seconds
[May 05, 21:23:34] #> Loading codec...
[May 05, 21:23:34] #> Loading IVF...
[May 05, 21:23:34] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...
[May 05, 21:23:34] #> Loading doclens...
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 3172.70it/s]
[May 05, 21:23:34] #> Loading codes and residuals...
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 342.45it/s]
[May 05, 21:23:34] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...
[May 05, 21:23:34] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...
/home/lknigge/.conda/envs/thesis-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
Searcher loaded!

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: If an individual consumes a significant amount of water, they will experience a state of hydration. Conversely, if excessive amounts of sugar are ingested, a sugar crash will ensue. It is known that at least one of the following statements is true: either the Jane consumes ample water or she will not experience a sugar crash. Can we say at least one of the following must always be true? (a) she will feel hydrated and (b) she doesn't eat too much sugar, 		 True, 		 None
#> Output IDs: torch.Size([110]), tensor([  101,     1,  2065,  2019,  3265, 16678,  2015,  1037,  3278,  3815,
         1997,  2300,  1010,  2027,  2097,  3325,  1037,  2110,  1997, 26018,
         3508,  1012, 18868,  1010,  2065, 11664,  8310,  1997,  5699,  2024,
        13749, 17944,  1010,  1037,  5699,  5823,  2097,  4372,  6342,  2063,
         1012,  2009,  2003,  2124,  2008,  2012,  2560,  2028,  1997,  1996,
         2206,  8635,  2003,  2995,  1024,  2593,  1996,  4869, 16678,  2015,
        20851,  2300,  2030,  2016,  2097,  2025,  3325,  1037,  5699,  5823,
         1012,  2064,  2057,  2360,  2012,  2560,  2028,  1997,  1996,  2206,
         2442,  2467,  2022,  2995,  1029,  1006,  1037,  1007,  2016,  2097,
         2514, 26018,  3064,  1998,  1006,  1038,  1007,  2016,  2987,  1005,
         1056,  4521,  2205,  2172,  5699,   102,   103,   103,   103,   103])
#> Output Mask: torch.Size([110]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])


total accuracy:  0.7596153846153846
filtered_accuracy:  0.7888888888888889

JOB STATISTICS
==============
Job ID: 11579406
Cluster: snellius
User/Group: lknigge/lknigge
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 24
CPU Utilized: 00:09:37
CPU Efficiency: 50.09% of 00:19:12 core-walltime
Job Wall-clock time: 00:00:48
Memory Utilized: 1.22 GB
Memory Efficiency: 2.90% of 42.00 GB (1.75 GB/core)
